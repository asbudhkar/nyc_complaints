{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\budhk\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['test', 'sqrt']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "# Code for classification model using Deep Learning\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "\n",
    "# For visualization\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# For data preprocessing\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "# Machine Learning library\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# For model definition\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from keras.layers import LSTM\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "%pylab inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_csv('model_data_f.csv', header=0, index_col=0)\n",
    "dataset.reset_index(inplace=True)\n",
    "dataset.drop(['JURISDICTION_CODE'],axis=1,inplace=True)\n",
    "values = dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80399 samples, validate on 39601 samples\n",
      "Epoch 1/30\n",
      "80399/80399 [==============================] - 8s 98us/step - loss: 2.0007 - acc: 0.4722 - val_loss: 1.2970 - val_acc: 0.5914\n",
      "Epoch 2/30\n",
      "80399/80399 [==============================] - 7s 90us/step - loss: 1.3741 - acc: 0.5781 - val_loss: 1.2272 - val_acc: 0.6010\n",
      "Epoch 3/30\n",
      "80399/80399 [==============================] - 7s 89us/step - loss: 1.3199 - acc: 0.5891 - val_loss: 1.1874 - val_acc: 0.6092\n",
      "Epoch 4/30\n",
      "80399/80399 [==============================] - 7s 89us/step - loss: 1.2960 - acc: 0.5912 - val_loss: 1.1912 - val_acc: 0.6055\n",
      "Epoch 5/30\n",
      "80399/80399 [==============================] - 7s 89us/step - loss: 1.2804 - acc: 0.5947 - val_loss: 1.1764 - val_acc: 0.6117\n",
      "Epoch 6/30\n",
      "80399/80399 [==============================] - 7s 92us/step - loss: 1.2692 - acc: 0.5982 - val_loss: 1.1703 - val_acc: 0.6131\n",
      "Epoch 7/30\n",
      "80399/80399 [==============================] - 7s 93us/step - loss: 1.2587 - acc: 0.5993 - val_loss: 1.1631 - val_acc: 0.6101\n",
      "Epoch 8/30\n",
      "80399/80399 [==============================] - 7s 90us/step - loss: 1.2527 - acc: 0.6002 - val_loss: 1.1591 - val_acc: 0.6099\n",
      "Epoch 9/30\n",
      "80399/80399 [==============================] - 7s 89us/step - loss: 1.2458 - acc: 0.6012 - val_loss: 1.1640 - val_acc: 0.6118\n",
      "Epoch 10/30\n",
      "80399/80399 [==============================] - 7s 89us/step - loss: 1.2433 - acc: 0.6028 - val_loss: 1.1621 - val_acc: 0.6117\n",
      "Epoch 11/30\n",
      "80399/80399 [==============================] - 7s 89us/step - loss: 1.2373 - acc: 0.6027 - val_loss: 1.1535 - val_acc: 0.6162\n",
      "Epoch 12/30\n",
      "80399/80399 [==============================] - 7s 90us/step - loss: 1.2318 - acc: 0.6041 - val_loss: 1.1475 - val_acc: 0.6151\n",
      "Epoch 13/30\n",
      "80399/80399 [==============================] - 7s 89us/step - loss: 1.2289 - acc: 0.6057 - val_loss: 1.1660 - val_acc: 0.6126\n",
      "Epoch 14/30\n",
      "80399/80399 [==============================] - 7s 90us/step - loss: 1.2232 - acc: 0.6075 - val_loss: 1.1545 - val_acc: 0.6147\n",
      "Epoch 15/30\n",
      "80399/80399 [==============================] - 7s 89us/step - loss: 1.2191 - acc: 0.6075 - val_loss: 1.1522 - val_acc: 0.6126\n",
      "Epoch 16/30\n",
      "80399/80399 [==============================] - 8s 94us/step - loss: 1.2168 - acc: 0.6076 - val_loss: 1.1532 - val_acc: 0.6126\n",
      "Epoch 17/30\n",
      "80399/80399 [==============================] - 7s 93us/step - loss: 1.2137 - acc: 0.6081 - val_loss: 1.1560 - val_acc: 0.6120\n",
      "Epoch 18/30\n",
      "80399/80399 [==============================] - 7s 93us/step - loss: 1.2097 - acc: 0.6090 - val_loss: 1.1492 - val_acc: 0.6152\n",
      "Epoch 19/30\n",
      "80399/80399 [==============================] - 7s 92us/step - loss: 1.2073 - acc: 0.6102 - val_loss: 1.1634 - val_acc: 0.6105\n",
      "Epoch 20/30\n",
      "80399/80399 [==============================] - 7s 90us/step - loss: 1.2035 - acc: 0.6111 - val_loss: 1.1491 - val_acc: 0.6146\n",
      "Epoch 21/30\n",
      "80399/80399 [==============================] - 7s 90us/step - loss: 1.2009 - acc: 0.6122 - val_loss: 1.1467 - val_acc: 0.6145\n",
      "Epoch 22/30\n",
      "80399/80399 [==============================] - 7s 91us/step - loss: 1.1969 - acc: 0.6140 - val_loss: 1.1539 - val_acc: 0.6159\n",
      "Epoch 23/30\n",
      "80399/80399 [==============================] - 7s 90us/step - loss: 1.1940 - acc: 0.6132 - val_loss: 1.1489 - val_acc: 0.6141\n",
      "Epoch 24/30\n",
      "80399/80399 [==============================] - 7s 89us/step - loss: 1.1913 - acc: 0.6146 - val_loss: 1.1593 - val_acc: 0.6094\n",
      "Epoch 25/30\n",
      "80399/80399 [==============================] - 7s 90us/step - loss: 1.1897 - acc: 0.6143 - val_loss: 1.1523 - val_acc: 0.6135\n",
      "Epoch 26/30\n",
      "80399/80399 [==============================] - 7s 90us/step - loss: 1.1863 - acc: 0.6152 - val_loss: 1.1532 - val_acc: 0.6127\n",
      "Epoch 27/30\n",
      "80399/80399 [==============================] - 7s 90us/step - loss: 1.1832 - acc: 0.6165 - val_loss: 1.1489 - val_acc: 0.6143\n",
      "Epoch 28/30\n",
      "80399/80399 [==============================] - 7s 90us/step - loss: 1.1805 - acc: 0.6161 - val_loss: 1.1533 - val_acc: 0.6144\n",
      "Epoch 29/30\n",
      "80399/80399 [==============================] - 7s 90us/step - loss: 1.1776 - acc: 0.6177 - val_loss: 1.1524 - val_acc: 0.6164\n",
      "Epoch 30/30\n",
      "80399/80399 [==============================] - 7s 90us/step - loss: 1.1759 - acc: 0.6185 - val_loss: 1.1556 - val_acc: 0.6146\n",
      "acc: 61.60%\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "n_train_hours = 120000\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[10000:, :]\n",
    "\n",
    "# Split into input and outputs\n",
    "train_X, train_y = train[:, 1:], train[:, 0]\n",
    "test_X, test_y = test[:, 1:], test[:, 0]\n",
    "\n",
    "# Encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_y)\n",
    "encoded_Y = encoder.transform(train_y)\n",
    "\n",
    "# Convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "# Encode class values as integers\n",
    "encoder1 = LabelEncoder()\n",
    "encoder1.fit(test_y)\n",
    "encoded_Y1 = encoder1.transform(test_y)\n",
    "\n",
    "# Convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y1 = np_utils.to_categorical(encoded_Y1)\n",
    "\n",
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(Dense(120, input_dim=111, activation='relu'))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dense(61,activation='softmax'))\n",
    "    \n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_X, dummy_y, validation_split=0.33, epochs=10, batch_size=200)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(test_X, dummy_y1, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
